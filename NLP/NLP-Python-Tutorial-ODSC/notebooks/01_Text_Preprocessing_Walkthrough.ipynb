{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "<tr>\n",
    "\n",
    "<th, style=\"background-color:white\">\n",
    "<img src=\"https://github.com/mlgill/ODSC_East_2017_PythonNLP/blob/master/assets/logo.png?raw=true\", width=140, height=100>\n",
    "</th>\n",
    "\n",
    "<th, style=\"background-color:white\">\n",
    "<div align=\"left\">\n",
    "<h1>Learning from Text: <br> Introduction to Natural Language Processing with Python</h1>  \n",
    "<h2>Michelle L. Gill, Ph.D.</h2>     \n",
    "Senior Data Scientist, Metis  \n",
    "ODSC East  \n",
    "May 3, 2017 \n",
    "</div>\n",
    "</th>\n",
    "\n",
    "</tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.274738Z",
     "start_time": "2017-05-03T10:15:39.993345Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from accessory_functions import nltk_path\n",
    "\n",
    "# Setup nltk corpora path\n",
    "nltk.data.path.insert(0, nltk_path)\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A Simple Corpus\n",
    "\n",
    "Create a simple corpus of three short documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.281454Z",
     "start_time": "2017-05-03T10:15:41.276506Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_orig = ['This is document one. I went running.',\n",
    "               'This is document two. She was a writer.',\n",
    "               'This document has a numerical entry: 4,000dollars.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalization\n",
    "\n",
    "Text normalization involves converting all text to lower case. It sometimes also involves removing numerical words from the corpus. One way to do both of these things is with regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.311436Z",
     "start_time": "2017-05-03T10:15:41.286312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is document one. i went running.',\n",
       " 'this is document two. she was a writer.',\n",
       " 'this document has a numerical entry: ,.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_alpha_num(corpus):\n",
    "    # convert to lower case\n",
    "    corpus = map(str.lower, corpus)\n",
    "    \n",
    "    # remove alpha-numerical words\n",
    "    corpus = map(lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", '', x), corpus)\n",
    "    return list(corpus)\n",
    "\n",
    "corpus = lower_alpha_num(corpus_orig)\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Punctuation\n",
    "\n",
    "Punctuation can also be removed with a regular expression using the `string` library which contains a list of (most) punctuation characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.328071Z",
     "start_time": "2017-05-03T10:15:41.313843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# the punctuation list\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.348116Z",
     "start_time": "2017-05-03T10:15:41.330476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is document one  i went running ',\n",
       " 'this is document two  she was a writer ',\n",
       " 'this document has a numerical entry    ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(corpus):\n",
    "    # regular expression to remove punctuation\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "    corpus = map(lambda x: punc_re.sub(' ', x), corpus)\n",
    "    return list(corpus)\n",
    "\n",
    "# don't store the results of the punctuation removal just yet\n",
    "remove_punct(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenization\n",
    "\n",
    "Documents can be tokenized by sentence or word also using `nltk`. \n",
    "\n",
    "Sentence tokenization is less commonly used, but will be demonstrated first. Note that sentence punctuation is required for correct tokenization, so the punctuation removal performed above can't be performed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.376042Z",
     "start_time": "2017-05-03T10:15:41.350152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this is document one.', 'i went running.'],\n",
       " ['this is document two.', 'she was a writer.'],\n",
       " ['this document has a numerical entry: ,.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "corpus_sent = map(sent_tokenize, corpus)\n",
    "\n",
    "list(corpus_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word tokenization is more common. The punctuation removal described above will now be added in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.388297Z",
     "start_time": "2017-05-03T10:15:41.378048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'document', 'one', 'i', 'went', 'running'],\n",
       " ['this', 'is', 'document', 'two', 'she', 'was', 'a', 'writer'],\n",
       " ['this', 'document', 'has', 'a', 'numerical', 'entry']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word_tokens(corpus):\n",
    "    return list(map(word_tokenize, corpus))\n",
    "\n",
    "corpus = word_tokens(remove_punct(corpus))\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stopword Removal\n",
    "\n",
    "Commonly used words, called \"stop words\" can be removed using `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.399823Z",
     "start_time": "2017-05-03T10:15:41.390050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to generalize a text preprocessing method so that it will work on either a list (i.e. single document) or a list of lists (multiple, tokenzied documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.408581Z",
     "start_time": "2017-05-03T10:15:41.401655Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generalize_fun(corpus, lambda_fun):\n",
    "    # must handle a list of lists (tokenized docs) and also a simple list\n",
    "    \n",
    "    if isinstance(corpus[0], list):\n",
    "        # list of lists\n",
    "        corpus = map(lambda_fun, corpus)\n",
    "    else:\n",
    "        # single list\n",
    "        corpus = lambda_fun(corpus)\n",
    "        \n",
    "    return list(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the stop words can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.424402Z",
     "start_time": "2017-05-03T10:15:41.410749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['document', 'one', 'went', 'running'],\n",
       " ['document', 'two', 'writer'],\n",
       " ['document', 'numerical', 'entry']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_sws(corpus):\n",
    "    # stopword removal\n",
    "    stop_words = stopwords.words('english')\n",
    "    filter_fun = lambda x: list(filter(lambda x: x not in stop_words, x))\n",
    "\n",
    "    corpus = generalize_fun(corpus, filter_fun)\n",
    "    return list(corpus)\n",
    "\n",
    "corpus = remove_sws(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parts of Speech Tagging\n",
    "\n",
    "Parts-of-speech (POS) tagging refers to the process of assigning tags, such as “noun” or “verb”, to words in documents.\n",
    "\n",
    "Example POS tags: \n",
    "\n",
    "WP: wh-pronoun (\"who\", \"what\")  \n",
    "VBZ: verb, 3rd person sing. present (\"takes\")  \n",
    "VBG: verb, gerund/present participle (\"taking\")  \n",
    "TO: to (\"to go\", \"to him\")   \n",
    "DT: determiner (\"the\", \"this\")  \n",
    "NN: noun, singular or mass (\"door\")  \n",
    ".: Punctuation (\".\", \"?\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.560839Z",
     "start_time": "2017-05-03T10:15:41.427988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('document', 'NN'), ('one', 'CD'), ('went', 'VBD'), ('running', 'VBG')],\n",
       " [('document', 'NN'), ('two', 'CD'), ('writer', 'NN')],\n",
       " [('document', 'NN'), ('numerical', 'JJ'), ('entry', 'NN')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_tag(corpus):        \n",
    "    return list(map(nltk.pos_tag, corpus))\n",
    "\n",
    "corpus_tagged = pos_tag(corpus)\n",
    "corpus_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stemming\n",
    "\n",
    "Stemming removes alternative work endings. It produces similar, but not identical, results to  lemmatization, which is a related technique. We will cover stemming here and lemmatization in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.577299Z",
     "start_time": "2017-05-03T10:15:41.562803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['document', 'one', 'went', 'run'],\n",
       " ['document', 'two', 'writer'],\n",
       " ['document', 'numer', 'entri']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def stem(corpus):\n",
    "    # perform stemming\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmer_fun = lambda x: list(map(stemmer.stem, x))\n",
    "\n",
    "    corpus = generalize_fun(corpus, stemmer_fun)\n",
    "    return list(corpus)\n",
    "\n",
    "stem(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. N-Grams\n",
    "\n",
    "N-grams are multi-word tokens whose incorporation into a model can help add word order as an important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.592999Z",
     "start_time": "2017-05-03T10:15:41.579914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['document one', 'one went', 'went running'],\n",
       " ['document two', 'two writer'],\n",
       " ['document numerical', 'numerical entry']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "def bigrams(corpus, ngram_size=2):\n",
    "    # create n-grams\n",
    "    ngram_fun = lambda x: list(map(' '.join, ngrams(x, ngram_size)))\n",
    "\n",
    "    corpus = generalize_fun(corpus, ngram_fun)\n",
    "    return list(corpus)\n",
    "\n",
    "bigrams(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Count Vectorizer: Converting Text to Numbers\n",
    "\n",
    "Scikit-learn's [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) converts tokenized words to a sparse count matrix. Count vectorizer will normalize and tokenize words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.601344Z",
     "start_time": "2017-05-03T10:15:41.595278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is document one. I went running.',\n",
       " 'This is document two. She was a writer.',\n",
       " 'This document has a numerical entry: 4,000dollars.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.632411Z",
     "start_time": "2017-05-03T10:15:41.603561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(corpus_orig)\n",
    "X = X.toarray()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is known as a document-term matrix. The rows correspond to each document and the columns correspond to feature counts. It's easiest to see the features by converting to a dataframe.\n",
    "\n",
    "Note that count vectorizer doesn't remove alpha-numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.673518Z",
     "start_time": "2017-05-03T10:15:41.643596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000dollars</th>\n",
       "      <th>document</th>\n",
       "      <th>entry</th>\n",
       "      <th>has</th>\n",
       "      <th>is</th>\n",
       "      <th>numerical</th>\n",
       "      <th>one</th>\n",
       "      <th>running</th>\n",
       "      <th>she</th>\n",
       "      <th>this</th>\n",
       "      <th>two</th>\n",
       "      <th>was</th>\n",
       "      <th>went</th>\n",
       "      <th>writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   000dollars  document  entry  has  is  numerical  one  running  she  this  \\\n",
       "0           0         1      0    0   1          0    1        1    0     1   \n",
       "1           0         1      0    0   1          0    0        0    1     1   \n",
       "2           1         1      1    1   0          1    0        0    0     1   \n",
       "\n",
       "   two  was  went  writer  \n",
       "0    0    0     1       0  \n",
       "1    1    1     0       1  \n",
       "2    0    0     0       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X,\n",
    "             columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, a custom preprocessor can be used to remove the alpha-numerical words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.707573Z",
     "start_time": "2017-05-03T10:15:41.677143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>entry</th>\n",
       "      <th>has</th>\n",
       "      <th>is</th>\n",
       "      <th>numerical</th>\n",
       "      <th>one</th>\n",
       "      <th>running</th>\n",
       "      <th>she</th>\n",
       "      <th>this</th>\n",
       "      <th>two</th>\n",
       "      <th>was</th>\n",
       "      <th>went</th>\n",
       "      <th>writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  entry  has  is  numerical  one  running  she  this  two  was  \\\n",
       "0         1      0    0   1          0    1        1    0     1    0    0   \n",
       "1         1      0    0   1          0    0        0    1     1    1    1   \n",
       "2         1      1    1   0          1    0        0    0     1    0    0   \n",
       "\n",
       "   went  writer  \n",
       "0     1       0  \n",
       "1     0       1  \n",
       "2     0       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_nums = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x.lower())\n",
    "\n",
    "cv = CountVectorizer(preprocessor=remove_nums)\n",
    "\n",
    "X = cv.fit_transform(corpus_orig).toarray()\n",
    "pd.DataFrame(X,\n",
    "             columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.713556Z",
     "start_time": "2017-05-03T10:15:41.709863Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid having to normalize in code below\n",
    "corpus_norm = lower_alpha_num(corpus_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count vectorizer can also return only binary values if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.748386Z",
     "start_time": "2017-05-03T10:15:41.715922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>entry</th>\n",
       "      <th>has</th>\n",
       "      <th>is</th>\n",
       "      <th>numerical</th>\n",
       "      <th>one</th>\n",
       "      <th>running</th>\n",
       "      <th>she</th>\n",
       "      <th>this</th>\n",
       "      <th>two</th>\n",
       "      <th>was</th>\n",
       "      <th>went</th>\n",
       "      <th>writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  entry  has  is  numerical  one  running  she  this  two  was  \\\n",
       "0         1      0    0   1          0    1        1    0     1    0    0   \n",
       "1         1      0    0   1          0    0        0    1     1    1    1   \n",
       "2         1      1    1   0          1    0        0    0     1    0    0   \n",
       "\n",
       "   went  writer  \n",
       "0     1       0  \n",
       "1     0       1  \n",
       "2     0       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "\n",
    "X = cv.fit_transform(corpus_norm).toarray()\n",
    "pd.DataFrame(X,\n",
    "             columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranges of n-grams can be added as additional features. The matrix is shown transposed for easier viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.769574Z",
     "start_time": "2017-05-03T10:15:41.750755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document has</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document one</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document two</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has numerical</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is document</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerical</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerical entry</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one went</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she was</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this document</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this is</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two she</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was writer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went running</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0  1  2\n",
       "document         1  1  1\n",
       "document has     0  0  1\n",
       "document one     1  0  0\n",
       "document two     0  1  0\n",
       "entry            0  0  1\n",
       "has              0  0  1\n",
       "has numerical    0  0  1\n",
       "is               1  1  0\n",
       "is document      1  1  0\n",
       "numerical        0  0  1\n",
       "numerical entry  0  0  1\n",
       "one              1  0  0\n",
       "one went         1  0  0\n",
       "running          1  0  0\n",
       "she              0  1  0\n",
       "she was          0  1  0\n",
       "this             1  1  1\n",
       "this document    0  0  1\n",
       "this is          1  1  0\n",
       "two              0  1  0\n",
       "two she          0  1  0\n",
       "was              0  1  0\n",
       "was writer       0  1  0\n",
       "went             1  0  0\n",
       "went running     1  0  0\n",
       "writer           0  1  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X = cv.fit_transform(corpus_norm).toarray()\n",
    "pd.DataFrame(X,\n",
    "             columns=cv.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, count vectorizer can automatically remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-03T10:15:41.797319Z",
     "start_time": "2017-05-03T10:15:41.771666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>entry</th>\n",
       "      <th>numerical</th>\n",
       "      <th>one</th>\n",
       "      <th>running</th>\n",
       "      <th>two</th>\n",
       "      <th>went</th>\n",
       "      <th>writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  entry  numerical  one  running  two  went  writer\n",
       "0         1      0          0    1        1    0     1       0\n",
       "1         1      0          0    0        0    1     0       1\n",
       "2         1      1          1    0        0    0     0       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "\n",
    "X = cv.fit_transform(corpus_norm).toarray()\n",
    "pd.DataFrame(X,\n",
    "             columns=cv.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
